{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atqZGIIyNSBb"
      },
      "source": [
        "#**Практическое задание №1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGBk36LpukIu",
        "outputId": "f164424b-cefd-4d1d-832c-42d0fba0cc6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "Successfully installed gdown-4.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -q tqdm\n",
        "!pip install --upgrade --no-cache-dir gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G5KkA1Nu5M9",
        "outputId": "ed56fa6c-9930-40bb-f851-31ac7344f0ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab2yCwDm7Fqb"
      },
      "outputs": [],
      "source": [
        "EVALUATE_ONLY = False\n",
        "TEST_ON_LARGE_DATASET = True\n",
        "TISSUE_CLASSES = ('ADI', 'BACK', 'DEB', 'LYM', 'MUC', 'MUS', 'NORM', 'STR', 'TUM')\n",
        "DATASETS_LINKS = {\n",
        "    # Закоментированные строки из оригинального ноутбука\n",
        "    # К сожалению оригинальные ссылки не работают из-за большого кол-ва скачиваний\n",
        "    # 'train': '1XtQzVQ5XbrfxpLHJuL0XBGJ5U7CS-cLi',\n",
        "    # https://drive.google.com/file/d/1ccAgGUs43hA6hf9rpV8fi84VLv_2uW8a/view?usp=sharing\n",
        "    'train': '1ccAgGUs43hA6hf9rpV8fi84VLv_2uW8a',\n",
        "    'train_small': '1qd45xXfDwdZjktLFwQb-et-mAaFeCzOR',\n",
        "    # 'train_tiny': '1I-2ZOuXLd4QwhZQQltp817Kn3J0Xgbui',\n",
        "    # https://drive.google.com/file/d/18jKz6GfnilfIYZHT-sASvPfU1BH6p2OU/view?usp=drive_link\n",
        "    'train_tiny': '18jKz6GfnilfIYZHT-sASvPfU1BH6p2OU',\n",
        "    # 'test': '1RfPou3pFKpuHDJZ-D9XDFzgvwpUBFlDr',\n",
        "    # https://drive.google.com/file/d/1brH5TzbTNUPKz3yoWS_RD4FW1xJc-dEK/view?usp=sharing\n",
        "    'test': '1brH5TzbTNUPKz3yoWS_RD4FW1xJc-dEK',\n",
        "    'test_small': '1wbRsog0n7uGlHIPGLhyN-PMeT2kdQ2lI',\n",
        "    # 'test_tiny': '1viiB0s041CNsAK4itvX8PnYthJ-MDnQc'\n",
        "    # https://drive.google.com/file/d/1bOavoin0mTiBhx8AYZhIkAa3YhEinbLa/view?usp=sharing\n",
        "    'test_tiny': '1bOavoin0mTiBhx8AYZhIkAa3YhEinbLa'\n",
        "}\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "SHUFFLE_BUFFER_SIZE = 100\n",
        "TRAIN_RATIO = 0.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLHQhqiSIyvK",
        "outputId": "eda905fb-5555-4798-a9d5-1a16bf02850b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-27 09:29:01.442637: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-27 09:29:02.166937: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from tqdm.notebook import tqdm\n",
        "from time import sleep\n",
        "from PIL import Image\n",
        "import IPython.display\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import gdown\n",
        "import cv2\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8N169efsw1ej"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "class Dataset:\n",
        "\n",
        "    def __init__(self, name, local = True):\n",
        "        self.name = name\n",
        "        self.is_loaded = False\n",
        "        if not local:\n",
        "            url = f\"https://drive.google.com/uc?export=download&confirm=pbef&id={DATASETS_LINKS[name]}\"\n",
        "            output = f'{name}.npz'\n",
        "            gdown.download(url, output, quiet=False)\n",
        "            print(f'Loading dataset {self.name} from npz.')\n",
        "            np_obj = np.load(f'{name}.npz')\n",
        "            self.images = np_obj['data']\n",
        "            self.labels = np_obj['labels']\n",
        "            self.n_files = self.images.shape[0]\n",
        "            self.is_loaded = True\n",
        "        else:\n",
        "            np_obj = np.load(f'datasets/{name}.npz')\n",
        "            self.images = np_obj['data']\n",
        "            self.labels = np_obj['labels']\n",
        "            self.n_files = self.images.shape[0]\n",
        "            self.is_loaded = True\n",
        "        print(f'Done. Dataset {name} consists of {self.n_files} images.')\n",
        "        self.train_inds = np.random.choice(self.n_files, int(self.n_files * TRAIN_RATIO), replace=False)\n",
        "        self.val_inds = np.setdiff1d(np.arange(self.n_files), self.train_inds)\n",
        "\n",
        "    def image(self, i):\n",
        "        # read i-th image in dataset and return it as numpy array\n",
        "        if self.is_loaded:\n",
        "            return self.images[i, :, :, :]\n",
        "\n",
        "    def images_seq(self, n=None):\n",
        "        # sequential access to images inside dataset (is needed for testing)\n",
        "        for i in range(self.n_files if not n else n):\n",
        "            yield self.image(i)\n",
        "\n",
        "    def random_image_with_label(self):\n",
        "        # get random image with label from dataset\n",
        "        i = np.random.randint(self.n_files)\n",
        "        return self.image(i), self.labels[i]\n",
        "\n",
        "    def random_batch_with_labels(self, n):\n",
        "        # create random batch of images with labels (is needed for training)\n",
        "        indices = np.random.choice(self.n_files, n)\n",
        "        imgs = []\n",
        "        for i in indices:\n",
        "            img = self.image(i)\n",
        "            imgs.append(self.image(i))\n",
        "        logits = np.array([self.labels[i] for i in indices])\n",
        "        return np.stack(imgs), logits\n",
        "\n",
        "    def random_batch_from_train_val(self, n, set_name='train'):\n",
        "        if set_name == 'train':\n",
        "            indices = np.random.choice(self.train_inds, n)\n",
        "        else:\n",
        "            indices = np.random.choice(self.val_inds, n)\n",
        "        imgs = []\n",
        "        for i in indices:\n",
        "            img = self.image(i)\n",
        "            imgs.append(self.image(i))\n",
        "        logits = np.array([self.labels[i] for i in indices])\n",
        "        return np.stack(imgs), logits\n",
        "\n",
        "\n",
        "    def image_with_label(self, i: int):\n",
        "        # return i-th image with label from dataset\n",
        "        return self.image(i), self.labels[i]\n",
        "\n",
        "    def train_val_index_split(self, train_ratio=0.8):\n",
        "        self.train_inds = np.random.choice(self.n_files, int(self.n_files * train_ratio), replace=False)\n",
        "        self.val_inds = np.setdiff1d(np.arange(self.n_files), self.train_inds)\n",
        "\n",
        "\n",
        "    def train_val_split(self, seed: int):\n",
        "        return tf.data.Dataset.from_tensor_slices((self.images, self.labels))\n",
        "        # train_dataset = tf.data.Dataset.from_tensor_slices((self.images, self.labels))\n",
        "        # train_ds, val_ds = keras.utils.split_dataset(train_dataset, left_size=0.8, shuffle=True)\n",
        "        # train_ds = train_ds.cache().shuffle(AUTOTUNE).batch(BATCH_SIZE)\n",
        "        # val_ds = val_ds.cache().batch(BATCH_SIZE)\n",
        "        # return train_ds, val_ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxR2BA_-wZak"
      },
      "outputs": [],
      "source": [
        "class MySequence(tf.keras.utils.Sequence):\n",
        "    def __init__(self, dataset: Dataset, set_name='train') -> None:\n",
        "      super().__init__()\n",
        "      self.dataset = dataset\n",
        "      self.leny = dataset.n_files // BATCH_SIZE\n",
        "      self.set_name = set_name\n",
        "\n",
        "    def __len__(self):\n",
        "      return self.leny\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      return self.dataset.random_batch_from_train_val(BATCH_SIZE, self.set_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5unQ7azTinCZ"
      },
      "outputs": [],
      "source": [
        "class Metrics:\n",
        "\n",
        "    @staticmethod\n",
        "    def accuracy(gt: List[int], pred: List[int]):\n",
        "        assert len(gt) == len(pred), 'gt and prediction should be of equal length'\n",
        "        return sum(int(i[0] == i[1]) for i in zip(gt, pred)) / len(gt)\n",
        "\n",
        "    @staticmethod\n",
        "    def accuracy_balanced(gt: List[int], pred: List[int]):\n",
        "        return balanced_accuracy_score(gt, pred)\n",
        "\n",
        "    @staticmethod\n",
        "    def print_all(gt: List[int], pred: List[int], info: str):\n",
        "        print(f'metrics for {info}:')\n",
        "        print('\\t accuracy {:.4f}:'.format(Metrics.accuracy(gt, pred)))\n",
        "        print('\\t balanced accuracy {:.4f}:'.format(Metrics.accuracy_balanced(gt, pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pkMiB6mJ7JQ"
      },
      "outputs": [],
      "source": [
        "class Model:\n",
        "\n",
        "    def __init__(self):\n",
        "        num_classes = len(TISSUE_CLASSES)\n",
        "\n",
        "        data_augmentation = keras.Sequential(\n",
        "            [\n",
        "                layers.RandomFlip(\"horizontal\",\n",
        "                                input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "                layers.RandomRotation(0.1),\n",
        "                layers.RandomZoom(0.1),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        efficient_netb0 = keras.applications.EfficientNetB0(include_top=True, weights=None, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "        self.model = Sequential()\n",
        "        self.model.add(data_augmentation)\n",
        "        self.model.add(efficient_netb0)\n",
        "        self.model.add(layers.Dropout(0.2))\n",
        "        self.model.add(layers.Dense(128, activation='relu', kernel_regularizer='l2'))\n",
        "        self.model.add(layers.Dense(num_classes))\n",
        "\n",
        "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "        self.model.summary()\n",
        "\n",
        "    def save(self, name: str):\n",
        "        pass\n",
        "\n",
        "    def load(self, name: str):\n",
        "        self.model = keras.models.load_model(f\"{name}.tf\")\n",
        "        # example demonstrating loading the model with name 'name' from gdrive using link\n",
        "        # name_to_id_dict = {\n",
        "        #     'best': '1S8bwrVgvtSzadEX2aLlyb3VTlD31UI4R'\n",
        "        # }\n",
        "        # output = f'{name}.npz'\n",
        "        # gdown.download(f'https://drive.google.com/uc?id={name_to_id_dict[name]}', output, quiet=False)\n",
        "        # np_obj = np.load(f'{name}.npz')\n",
        "        # print(np_obj['data'])\n",
        "\n",
        "    def train(self, dataset: Dataset):\n",
        "        train_seq = MySequence(dataset, set_name = 'train')\n",
        "        val_seq = MySequence(dataset, set_name = 'val')\n",
        "\n",
        "        checkpoint = ModelCheckpoint(\"best_model27.tf\", monitor='loss', verbose=1,\n",
        "                    save_best_only=True, mode='auto', period=1)\n",
        "\n",
        "        epochs=30\n",
        "        self.history = self.model.fit(\n",
        "            train_seq,\n",
        "            validation_data=val_seq,\n",
        "            epochs=epochs,\n",
        "            verbose=1,\n",
        "            # steps_per_epoch = 15,\n",
        "            # validation_steps = 7,\n",
        "            callbacks=[checkpoint]\n",
        "        )\n",
        "\n",
        "    def train_tmp(self, train_ds):\n",
        "        checkpoint = ModelCheckpoint(\"best_model.tf\", monitor='loss', verbose=1,\n",
        "                    save_best_only=True, mode='auto', period=1)\n",
        "\n",
        "        epochs=1\n",
        "        self.history = self.model.fit(\n",
        "            train_ds,\n",
        "            epochs=epochs,\n",
        "            verbose=1,\n",
        "            # steps_per_epoch = 15,\n",
        "            # validation_steps = 7,\n",
        "            callbacks=[checkpoint]\n",
        "        )\n",
        "\n",
        "    def continue_train(self, name: str, dataset: Dataset):\n",
        "        self.load(name)\n",
        "        self.train(dataset)\n",
        "\n",
        "    def test_on_dataset(self, dataset: Dataset, limit=None):\n",
        "        # you can upgrade this code if you want to speed up testing using batches\n",
        "        # predictions = []\n",
        "        # n = dataset.n_files if not limit else int(dataset.n_files * limit)\n",
        "        # for img in tqdm(dataset.images_seq(n), total=n):\n",
        "        #     predictions.append(self.test_on_image(img))\n",
        "        # return predictions\n",
        "        return self.model.predict(dataset.images).argmax(axis=-1)\n",
        "\n",
        "\n",
        "    def test_on_image(self, img: np.ndarray):\n",
        "        # todo: replace this code\n",
        "        prediction = self.model.predict(img)\n",
        "        return prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cTOuZD01Up6",
        "outputId": "db309294-f406-4008-9f65-ed37092a789b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done. Dataset train consists of 18000 images.\n",
            "Done. Dataset test consists of 4500 images.\n"
          ]
        }
      ],
      "source": [
        "d_train = Dataset('train')\n",
        "d_test = Dataset('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "vJfLZaUK2ZKW",
        "outputId": "4fb18baa-b5df-43fa-d7d0-47a4a97214a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-27 09:29:35.106268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3489 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " efficientnetb0 (Functional  (None, 1000)              5330571   \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1000)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               128128    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 9)                 1161      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5459860 (20.83 MB)\n",
            "Trainable params: 5417837 (20.67 MB)\n",
            "Non-trainable params: 42023 (164.16 KB)\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-27 09:29:56.827197: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/efficientnetb0/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
            "2023-11-27 09:29:58.572048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8906\n",
            "2023-11-27 09:29:58.918197: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x9b18180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-11-27 09:29:58.918223: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1050, Compute Capability 6.1\n",
            "2023-11-27 09:29:58.922200: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2023-11-27 09:29:59.025574: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6813 - accuracy: 0.7749\n",
            "Epoch 1: loss improved from inf to 0.68129, saving model to best_model27.tf\n",
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1125/1125 [==============================] - 554s 465ms/step - loss: 0.6813 - accuracy: 0.7749 - val_loss: 0.4365 - val_accuracy: 0.8902\n",
            "Epoch 2/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.7716\n",
            "Epoch 2: loss did not improve from 0.68129\n",
            "1125/1125 [==============================] - 501s 446ms/step - loss: 0.6907 - accuracy: 0.7716 - val_loss: 0.4353 - val_accuracy: 0.8587\n",
            "Epoch 3/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6857 - accuracy: 0.7687\n",
            "Epoch 3: loss did not improve from 0.68129\n",
            "1125/1125 [==============================] - 501s 445ms/step - loss: 0.6857 - accuracy: 0.7687 - val_loss: 0.4360 - val_accuracy: 0.8558\n",
            "Epoch 4/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6789 - accuracy: 0.7718\n",
            "Epoch 4: loss improved from 0.68129 to 0.67893, saving model to best_model27.tf\n",
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1125/1125 [==============================] - 522s 464ms/step - loss: 0.6789 - accuracy: 0.7718 - val_loss: 0.4805 - val_accuracy: 0.8376\n",
            "Epoch 5/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6823 - accuracy: 0.7697\n",
            "Epoch 5: loss did not improve from 0.67893\n",
            "1125/1125 [==============================] - 501s 446ms/step - loss: 0.6823 - accuracy: 0.7697 - val_loss: 0.4548 - val_accuracy: 0.8533\n",
            "Epoch 6/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6698 - accuracy: 0.7732\n",
            "Epoch 6: loss improved from 0.67893 to 0.66977, saving model to best_model27.tf\n",
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1125/1125 [==============================] - 525s 467ms/step - loss: 0.6698 - accuracy: 0.7732 - val_loss: 0.4876 - val_accuracy: 0.8654\n",
            "Epoch 7/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6620 - accuracy: 0.7737\n",
            "Epoch 7: loss improved from 0.66977 to 0.66198, saving model to best_model27.tf\n",
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1125/1125 [==============================] - 523s 465ms/step - loss: 0.6620 - accuracy: 0.7737 - val_loss: 0.5867 - val_accuracy: 0.8388\n",
            "Epoch 8/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6522 - accuracy: 0.7757\n",
            "Epoch 8: loss improved from 0.66198 to 0.65224, saving model to best_model27.tf\n",
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1125/1125 [==============================] - 523s 465ms/step - loss: 0.6522 - accuracy: 0.7757 - val_loss: 0.4238 - val_accuracy: 0.8839\n",
            "Epoch 9/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6545 - accuracy: 0.7779\n",
            "Epoch 9: loss did not improve from 0.65224\n",
            "1125/1125 [==============================] - 502s 446ms/step - loss: 0.6545 - accuracy: 0.7779 - val_loss: 0.4600 - val_accuracy: 0.8851\n",
            "Epoch 10/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6609 - accuracy: 0.7704\n",
            "Epoch 10: loss did not improve from 0.65224\n",
            "1125/1125 [==============================] - 501s 446ms/step - loss: 0.6609 - accuracy: 0.7704 - val_loss: 0.5966 - val_accuracy: 0.8488\n",
            "Epoch 11/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6463 - accuracy: 0.7827\n",
            "Epoch 11: loss improved from 0.65224 to 0.64629, saving model to best_model27.tf\n",
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1125/1125 [==============================] - 523s 465ms/step - loss: 0.6463 - accuracy: 0.7827 - val_loss: 0.4305 - val_accuracy: 0.8847\n",
            "Epoch 12/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6476 - accuracy: 0.7819\n",
            "Epoch 12: loss did not improve from 0.64629\n",
            "1125/1125 [==============================] - 502s 446ms/step - loss: 0.6476 - accuracy: 0.7819 - val_loss: 0.6888 - val_accuracy: 0.8137\n",
            "Epoch 13/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6472 - accuracy: 0.7828\n",
            "Epoch 13: loss did not improve from 0.64629\n",
            "1125/1125 [==============================] - 501s 446ms/step - loss: 0.6472 - accuracy: 0.7828 - val_loss: 0.5150 - val_accuracy: 0.8206\n",
            "Epoch 14/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6539 - accuracy: 0.7817\n",
            "Epoch 14: loss did not improve from 0.64629\n",
            "1125/1125 [==============================] - 501s 445ms/step - loss: 0.6539 - accuracy: 0.7817 - val_loss: 0.4575 - val_accuracy: 0.8822\n",
            "Epoch 15/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6466 - accuracy: 0.7857\n",
            "Epoch 15: loss did not improve from 0.64629\n",
            "1125/1125 [==============================] - 501s 446ms/step - loss: 0.6466 - accuracy: 0.7857 - val_loss: 0.4377 - val_accuracy: 0.8474\n",
            "Epoch 16/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6443 - accuracy: 0.7929\n",
            "Epoch 16: loss improved from 0.64629 to 0.64432, saving model to best_model27.tf\n",
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1125/1125 [==============================] - 523s 465ms/step - loss: 0.6443 - accuracy: 0.7929 - val_loss: 0.4356 - val_accuracy: 0.9077\n",
            "Epoch 17/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6452 - accuracy: 0.7943\n",
            "Epoch 17: loss did not improve from 0.64432\n",
            "1125/1125 [==============================] - 502s 446ms/step - loss: 0.6452 - accuracy: 0.7943 - val_loss: 0.4857 - val_accuracy: 0.9083\n",
            "Epoch 18/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6345 - accuracy: 0.8041\n",
            "Epoch 18: loss improved from 0.64432 to 0.63447, saving model to best_model27.tf\n",
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1125/1125 [==============================] - 522s 464ms/step - loss: 0.6345 - accuracy: 0.8041 - val_loss: 0.3936 - val_accuracy: 0.9290\n",
            "Epoch 19/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6258 - accuracy: 0.8022\n",
            "Epoch 19: loss improved from 0.63447 to 0.62576, saving model to best_model27.tf\n",
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1125/1125 [==============================] - 524s 466ms/step - loss: 0.6258 - accuracy: 0.8022 - val_loss: 0.4156 - val_accuracy: 0.8964\n",
            "Epoch 20/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6085 - accuracy: 0.8145\n",
            "Epoch 20: loss improved from 0.62576 to 0.60848, saving model to best_model27.tf\n",
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1125/1125 [==============================] - 523s 465ms/step - loss: 0.6085 - accuracy: 0.8145 - val_loss: 0.4514 - val_accuracy: 0.9229\n",
            "Epoch 21/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6098 - accuracy: 0.8128\n",
            "Epoch 21: loss did not improve from 0.60848\n",
            "1125/1125 [==============================] - 502s 446ms/step - loss: 0.6098 - accuracy: 0.8128 - val_loss: 0.3941 - val_accuracy: 0.9387\n",
            "Epoch 22/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6158 - accuracy: 0.8130\n",
            "Epoch 22: loss did not improve from 0.60848\n",
            "1125/1125 [==============================] - 501s 445ms/step - loss: 0.6158 - accuracy: 0.8130 - val_loss: 0.3805 - val_accuracy: 0.9434\n",
            "Epoch 23/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.5964 - accuracy: 0.8213\n",
            "Epoch 23: loss improved from 0.60848 to 0.59641, saving model to best_model27.tf\n",
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1125/1125 [==============================] - 523s 465ms/step - loss: 0.5964 - accuracy: 0.8213 - val_loss: 0.4128 - val_accuracy: 0.9246\n",
            "Epoch 24/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.5807 - accuracy: 0.8226\n",
            "Epoch 24: loss improved from 0.59641 to 0.58070, saving model to best_model27.tf\n",
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1125/1125 [==============================] - 522s 464ms/step - loss: 0.5807 - accuracy: 0.8226 - val_loss: 0.3664 - val_accuracy: 0.9417\n",
            "Epoch 25/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.5821 - accuracy: 0.8182\n",
            "Epoch 25: loss did not improve from 0.58070\n",
            "1125/1125 [==============================] - 503s 447ms/step - loss: 0.5821 - accuracy: 0.8182 - val_loss: 0.4175 - val_accuracy: 0.9213\n",
            "Epoch 26/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.5772 - accuracy: 0.8184\n",
            "Epoch 26: loss improved from 0.58070 to 0.57720, saving model to best_model27.tf\n",
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1125/1125 [==============================] - 525s 467ms/step - loss: 0.5772 - accuracy: 0.8184 - val_loss: 0.3766 - val_accuracy: 0.9405\n",
            "Epoch 27/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.5702 - accuracy: 0.8202\n",
            "Epoch 27: loss improved from 0.57720 to 0.57019, saving model to best_model27.tf\n",
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1125/1125 [==============================] - 527s 469ms/step - loss: 0.5702 - accuracy: 0.8202 - val_loss: 0.3449 - val_accuracy: 0.9535\n",
            "Epoch 28/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.5727 - accuracy: 0.8217\n",
            "Epoch 28: loss did not improve from 0.57019\n",
            "1125/1125 [==============================] - 506s 450ms/step - loss: 0.5727 - accuracy: 0.8217 - val_loss: 0.3317 - val_accuracy: 0.9585\n",
            "Epoch 29/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.5682 - accuracy: 0.8176\n",
            "Epoch 29: loss improved from 0.57019 to 0.56824, saving model to best_model27.tf\n",
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1125/1125 [==============================] - 534s 474ms/step - loss: 0.5682 - accuracy: 0.8176 - val_loss: 0.3850 - val_accuracy: 0.9459\n",
            "Epoch 30/30\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.5555 - accuracy: 0.8216\n",
            "Epoch 30: loss improved from 0.56824 to 0.55551, saving model to best_model27.tf\n",
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model27.tf/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
            "1125/1125 [==============================] - 540s 480ms/step - loss: 0.5555 - accuracy: 0.8216 - val_loss: 0.3271 - val_accuracy: 0.9617\n"
          ]
        }
      ],
      "source": [
        "new_model = Model()\n",
        "new_model.continue_train('best_model', d_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdHMKAxVE8aT",
        "outputId": "4500b28a-3ff4-4770-aaac-171a32a2809d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_2 (Sequential)   (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " efficientnetb0 (Functional  (None, 1000)              5330571   \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               128128    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 9)                 1161      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5459860 (20.83 MB)\n",
            "Trainable params: 5417837 (20.67 MB)\n",
            "Non-trainable params: 42023 (164.16 KB)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-27 13:48:52.001543: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 677376000 exceeds 10% of free system memory.\n",
            "2023-11-27 13:48:52.490769: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 677376000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "141/141 [==============================] - 26s 162ms/step\n",
            "metrics for test:\n",
            "\t accuracy 0.9600:\n",
            "\t balanced accuracy 0.9600:\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.load('best_model27')\n",
        "pred_1 = model.test_on_dataset(d_test, limit=0.1)\n",
        "Metrics.print_all(d_test.labels, pred_1, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBi0XpXg8_wq",
        "outputId": "43808d0f-4c09-47af-89f2-9a6442a35604"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetb0 (Functional  (None, 1000)              5330571   \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1000)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               128128    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 9)                 1161      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5459860 (20.83 MB)\n",
            "Trainable params: 5417837 (20.67 MB)\n",
            "Non-trainable params: 42023 (164.16 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "if not EVALUATE_ONLY:\n",
        "    model.train(d_train)\n",
        "    model.save('best_model')\n",
        "else:\n",
        "    #todo: your link goes here\n",
        "    model.load('best_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcM2EiRMVP93"
      },
      "source": [
        "Пример тестирования модели на части набора данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "I0AqmeLEKqrs",
        "outputId": "4521afa7-208c-44f6-aa92-d93a36a16834"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 75ms/step\n",
            "metrics for 10% of test:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-bd8e063dbbca>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mMetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'10% of test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-e71ce1dade46>\u001b[0m in \u001b[0;36mprint_all\u001b[0;34m(gt, pred, info)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'metrics for {info}:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t accuracy {:.4f}:'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t balanced accuracy {:.4f}:'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_balanced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-e71ce1dade46>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(gt, pred)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gt and prediction should be of equal length'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-e71ce1dade46>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gt and prediction should be of equal length'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
          ]
        }
      ],
      "source": [
        "# evaluating model on 10% of test dataset\n",
        "\n",
        "pred_1 = model.test_on_dataset(d_test, limit=0.1)\n",
        "Metrics.print_all(d_test.labels[:len(pred_1)], pred_1, '10% of test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "vfqvnPa1q_UC",
        "outputId": "1d5b3276-5e6d-4601-88a5-b8afbbd9aac7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 8s 2s/step\n",
            "metrics for test:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2c31223b9e77>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mMetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-e71ce1dade46>\u001b[0m in \u001b[0;36mprint_all\u001b[0;34m(gt, pred, info)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'metrics for {info}:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t accuracy {:.4f}:'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t balanced accuracy {:.4f}:'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_balanced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-e71ce1dade46>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(gt, pred)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gt and prediction should be of equal length'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-e71ce1dade46>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gt and prediction should be of equal length'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
          ]
        }
      ],
      "source": [
        "pred_1 = model.test_on_dataset(d_test, limit=0.1)\n",
        "Metrics.print_all(d_test.labels, pred_1, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLLWLGQNFmZD",
        "outputId": "ab29d5f9-2d33-428e-80dc-e17efec131d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-5.0413021e-04, -2.4318264e-03, -1.7521996e-03,  3.1518488e-05,\n",
              "         2.1762779e-04,  2.0734109e-03, -5.3923373e-04, -1.3230898e-03,\n",
              "        -1.2664620e-03],\n",
              "       [-5.0413015e-04, -2.4318269e-03, -1.7521998e-03,  3.1518837e-05,\n",
              "         2.1762872e-04,  2.0734090e-03, -5.3923327e-04, -1.3230912e-03,\n",
              "        -1.2664617e-03],\n",
              "       [-5.0412992e-04, -2.4318260e-03, -1.7521998e-03,  3.1519710e-05,\n",
              "         2.1762837e-04,  2.0734109e-03, -5.3923286e-04, -1.3230894e-03,\n",
              "        -1.2664617e-03],\n",
              "       [-5.0413038e-04, -2.4318271e-03, -1.7521987e-03,  3.1517353e-05,\n",
              "         2.1762773e-04,  2.0734104e-03, -5.3923368e-04, -1.3230905e-03,\n",
              "        -1.2664614e-03],\n",
              "       [-5.0413178e-04, -2.4318264e-03, -1.7522005e-03,  3.1519274e-05,\n",
              "         2.1762855e-04,  2.0734114e-03, -5.3923245e-04, -1.3230873e-03,\n",
              "        -1.2664618e-03],\n",
              "       [-5.0413166e-04, -2.4318276e-03, -1.7522029e-03,  3.1521864e-05,\n",
              "         2.1763152e-04,  2.0734114e-03, -5.3923490e-04, -1.3230838e-03,\n",
              "        -1.2664606e-03],\n",
              "       [-5.0413091e-04, -2.4318264e-03, -1.7521996e-03,  3.1518226e-05,\n",
              "         2.1762849e-04,  2.0734095e-03, -5.3923309e-04, -1.3230901e-03,\n",
              "        -1.2664618e-03],\n",
              "       [-5.0412945e-04, -2.4318271e-03, -1.7521996e-03,  3.1517819e-05,\n",
              "         2.1762872e-04,  2.0734090e-03, -5.3923420e-04, -1.3230896e-03,\n",
              "        -1.2664619e-03],\n",
              "       [-5.0412992e-04, -2.4318264e-03, -1.7522005e-03,  3.1517673e-05,\n",
              "         2.1762855e-04,  2.0734114e-03, -5.3923368e-04, -1.3230896e-03,\n",
              "        -1.2664627e-03],\n",
              "       [-5.0413125e-04, -2.4318264e-03, -1.7522003e-03,  3.1520525e-05,\n",
              "         2.1762936e-04,  2.0734114e-03, -5.3923408e-04, -1.3230903e-03,\n",
              "        -1.2664606e-03],\n",
              "       [-5.0413015e-04, -2.4318262e-03, -1.7521989e-03,  3.1518051e-05,\n",
              "         2.1762704e-04,  2.0734100e-03, -5.3923350e-04, -1.3230905e-03,\n",
              "        -1.2664621e-03],\n",
              "       [-5.0412992e-04, -2.4318269e-03, -1.7521989e-03,  3.1517673e-05,\n",
              "         2.1762738e-04,  2.0734104e-03, -5.3923368e-04, -1.3230901e-03,\n",
              "        -1.2664625e-03],\n",
              "       [-5.0413358e-04, -2.4318260e-03, -1.7522045e-03,  3.1521718e-05,\n",
              "         2.1763181e-04,  2.0734139e-03, -5.3923408e-04, -1.3230849e-03,\n",
              "        -1.2664592e-03],\n",
              "       [-5.0413271e-04, -2.4318227e-03, -1.7522022e-03,  3.1518750e-05,\n",
              "         2.1763297e-04,  2.0734216e-03, -5.3923432e-04, -1.3230810e-03,\n",
              "        -1.2664580e-03],\n",
              "       [-5.0412992e-04, -2.4318264e-03, -1.7521987e-03,  3.1517586e-05,\n",
              "         2.1762721e-04,  2.0734100e-03, -5.3923356e-04, -1.3230898e-03,\n",
              "        -1.2664623e-03],\n",
              "       [-5.0413352e-04, -2.4318267e-03, -1.7522017e-03,  3.1522039e-05,\n",
              "         2.1763064e-04,  2.0734114e-03, -5.3923327e-04, -1.3230868e-03,\n",
              "        -1.2664605e-03],\n",
              "       [-5.0413224e-04, -2.4318260e-03, -1.7522003e-03,  3.1520554e-05,\n",
              "         2.1762907e-04,  2.0734097e-03, -5.3923257e-04, -1.3230884e-03,\n",
              "        -1.2664616e-03],\n",
              "       [-5.0412992e-04, -2.4318264e-03, -1.7521987e-03,  3.1517702e-05,\n",
              "         2.1762715e-04,  2.0734100e-03, -5.3923373e-04, -1.3230896e-03,\n",
              "        -1.2664624e-03],\n",
              "       [-5.0412974e-04, -2.4318267e-03, -1.7521991e-03,  3.1517731e-05,\n",
              "         2.1762704e-04,  2.0734100e-03, -5.3923362e-04, -1.3230901e-03,\n",
              "        -1.2664620e-03],\n",
              "       [-5.0413422e-04, -2.4318264e-03, -1.7522031e-03,  3.1522097e-05,\n",
              "         2.1763152e-04,  2.0734137e-03, -5.3923373e-04, -1.3230838e-03,\n",
              "        -1.2664592e-03],\n",
              "       [-5.0413306e-04, -2.4318276e-03, -1.7522031e-03,  3.1522592e-05,\n",
              "         2.1763064e-04,  2.0734102e-03, -5.3923356e-04, -1.3230873e-03,\n",
              "        -1.2664605e-03],\n",
              "       [-5.0413382e-04, -2.4318267e-03, -1.7522019e-03,  3.1522504e-05,\n",
              "         2.1763088e-04,  2.0734109e-03, -5.3923356e-04, -1.3230863e-03,\n",
              "        -1.2664602e-03],\n",
              "       [-5.0413399e-04, -2.4318262e-03, -1.7522031e-03,  3.1522621e-05,\n",
              "         2.1763099e-04,  2.0734118e-03, -5.3923280e-04, -1.3230863e-03,\n",
              "        -1.2664602e-03],\n",
              "       [-5.0413294e-04, -2.4318260e-03, -1.7522022e-03,  3.1519623e-05,\n",
              "         2.1762977e-04,  2.0734095e-03, -5.3923379e-04, -1.3230880e-03,\n",
              "        -1.2664611e-03],\n",
              "       [-5.0413358e-04, -2.4318262e-03, -1.7522015e-03,  3.1521777e-05,\n",
              "         2.1763128e-04,  2.0734104e-03, -5.3923338e-04, -1.3230856e-03,\n",
              "        -1.2664599e-03],\n",
              "       [-5.0413300e-04, -2.4318278e-03, -1.7522022e-03,  3.1521602e-05,\n",
              "         2.1763047e-04,  2.0734100e-03, -5.3923338e-04, -1.3230880e-03,\n",
              "        -1.2664613e-03],\n",
              "       [-5.0413137e-04, -2.4318264e-03, -1.7522015e-03,  3.1520700e-05,\n",
              "         2.1762878e-04,  2.0734104e-03, -5.3923368e-04, -1.3230887e-03,\n",
              "        -1.2664623e-03],\n",
              "       [-5.0413329e-04, -2.4318267e-03, -1.7522029e-03,  3.1522533e-05,\n",
              "         2.1763064e-04,  2.0734118e-03, -5.3923478e-04, -1.3230870e-03,\n",
              "        -1.2664602e-03],\n",
              "       [-5.0413318e-04, -2.4318253e-03, -1.7522019e-03,  3.1521748e-05,\n",
              "         2.1762913e-04,  2.0734109e-03, -5.3923391e-04, -1.3230875e-03,\n",
              "        -1.2664606e-03],\n",
              "       [-5.0413271e-04, -2.4318269e-03, -1.7522010e-03,  3.1519390e-05,\n",
              "         2.1763041e-04,  2.0734097e-03, -5.3923373e-04, -1.3230877e-03,\n",
              "        -1.2664595e-03],\n",
              "       [-5.0413253e-04, -2.4318274e-03, -1.7522015e-03,  3.1522301e-05,\n",
              "         2.1763105e-04,  2.0734109e-03, -5.3923315e-04, -1.3230863e-03,\n",
              "        -1.2664603e-03],\n",
              "       [-5.0413125e-04, -2.4318253e-03, -1.7522008e-03,  3.1519390e-05,\n",
              "         2.1762861e-04,  2.0734123e-03, -5.3923205e-04, -1.3230880e-03,\n",
              "        -1.2664597e-03],\n",
              "       [-5.0413312e-04, -2.4318264e-03, -1.7522017e-03,  3.1520525e-05,\n",
              "         2.1762925e-04,  2.0734118e-03, -5.3923362e-04, -1.3230870e-03,\n",
              "        -1.2664611e-03],\n",
              "       [-5.0413283e-04, -2.4318264e-03, -1.7522015e-03,  3.1520904e-05,\n",
              "         2.1763094e-04,  2.0734104e-03, -5.3923216e-04, -1.3230863e-03,\n",
              "        -1.2664597e-03],\n",
              "       [-5.0413457e-04, -2.4318250e-03, -1.7522033e-03,  3.1520874e-05,\n",
              "         2.1763082e-04,  2.0734123e-03, -5.3923321e-04, -1.3230849e-03,\n",
              "        -1.2664609e-03],\n",
              "       [-5.0413102e-04, -2.4318260e-03, -1.7522010e-03,  3.1520758e-05,\n",
              "         2.1762931e-04,  2.0734125e-03, -5.3923385e-04, -1.3230889e-03,\n",
              "        -1.2664604e-03],\n",
              "       [-5.0413248e-04, -2.4318260e-03, -1.7522022e-03,  3.1522504e-05,\n",
              "         2.1763030e-04,  2.0734128e-03, -5.3923513e-04, -1.3230870e-03,\n",
              "        -1.2664599e-03],\n",
              "       [-5.0413352e-04, -2.4318267e-03, -1.7522017e-03,  3.1522824e-05,\n",
              "         2.1763105e-04,  2.0734116e-03, -5.3923455e-04, -1.3230868e-03,\n",
              "        -1.2664613e-03],\n",
              "       [-5.0413405e-04, -2.4318260e-03, -1.7522022e-03,  3.1520147e-05,\n",
              "         2.1763105e-04,  2.0734109e-03, -5.3923356e-04, -1.3230854e-03,\n",
              "        -1.2664603e-03],\n",
              "       [-5.0413364e-04, -2.4318276e-03, -1.7522019e-03,  3.1520438e-05,\n",
              "         2.1763053e-04,  2.0734104e-03, -5.3923257e-04, -1.3230875e-03,\n",
              "        -1.2664611e-03],\n",
              "       [-5.0413300e-04, -2.4318271e-03, -1.7522010e-03,  3.1521195e-05,\n",
              "         2.1763047e-04,  2.0734100e-03, -5.3923210e-04, -1.3230884e-03,\n",
              "        -1.2664595e-03],\n",
              "       [-5.0413178e-04, -2.4318260e-03, -1.7522001e-03,  3.1521311e-05,\n",
              "         2.1762948e-04,  2.0734109e-03, -5.3923298e-04, -1.3230884e-03,\n",
              "        -1.2664616e-03],\n",
              "       [-5.0413155e-04, -2.4318269e-03, -1.7521996e-03,  3.1518488e-05,\n",
              "         2.1762919e-04,  2.0734114e-03, -5.3923292e-04, -1.3230891e-03,\n",
              "        -1.2664598e-03],\n",
              "       [-5.0413236e-04, -2.4318274e-03, -1.7522012e-03,  3.1520467e-05,\n",
              "         2.1762995e-04,  2.0734104e-03, -5.3923292e-04, -1.3230880e-03,\n",
              "        -1.2664601e-03],\n",
              "       [-5.0413201e-04, -2.4318269e-03, -1.7522012e-03,  3.1520642e-05,\n",
              "         2.1762942e-04,  2.0734109e-03, -5.3923274e-04, -1.3230884e-03,\n",
              "        -1.2664612e-03],\n",
              "       [-5.0413213e-04, -2.4318262e-03, -1.7522010e-03,  3.1521049e-05,\n",
              "         2.1762925e-04,  2.0734104e-03, -5.3923298e-04, -1.3230877e-03,\n",
              "        -1.2664613e-03],\n",
              "       [-5.0413347e-04, -2.4318283e-03, -1.7522029e-03,  3.1523494e-05,\n",
              "         2.1763187e-04,  2.0734118e-03, -5.3923379e-04, -1.3230863e-03,\n",
              "        -1.2664599e-03],\n",
              "       [-5.0413160e-04, -2.4318262e-03, -1.7522012e-03,  3.1521748e-05,\n",
              "         2.1762989e-04,  2.0734118e-03, -5.3923344e-04, -1.3230884e-03,\n",
              "        -1.2664626e-03],\n",
              "       [-5.0413114e-04, -2.4318262e-03, -1.7521998e-03,  3.1519536e-05,\n",
              "         2.1762878e-04,  2.0734097e-03, -5.3923292e-04, -1.3230891e-03,\n",
              "        -1.2664612e-03],\n",
              "       [-5.0413120e-04, -2.4318267e-03, -1.7521994e-03,  3.1518342e-05,\n",
              "         2.1762849e-04,  2.0734104e-03, -5.3923263e-04, -1.3230884e-03,\n",
              "        -1.2664620e-03],\n",
              "       [-5.0413120e-04, -2.4318278e-03, -1.7522022e-03,  3.1520176e-05,\n",
              "         2.1762948e-04,  2.0734111e-03, -5.3923402e-04, -1.3230887e-03,\n",
              "        -1.2664609e-03],\n",
              "       [-5.0413207e-04, -2.4318274e-03, -1.7522022e-03,  3.1521282e-05,\n",
              "         2.1763192e-04,  2.0734121e-03, -5.3923496e-04, -1.3230875e-03,\n",
              "        -1.2664613e-03],\n",
              "       [-5.0413271e-04, -2.4318276e-03, -1.7522024e-03,  3.1521980e-05,\n",
              "         2.1763088e-04,  2.0734104e-03, -5.3923402e-04, -1.3230868e-03,\n",
              "        -1.2664602e-03],\n",
              "       [-5.0413364e-04, -2.4318253e-03, -1.7522031e-03,  3.1522679e-05,\n",
              "         2.1763128e-04,  2.0734109e-03, -5.3923466e-04, -1.3230868e-03,\n",
              "        -1.2664619e-03],\n",
              "       [-5.0413137e-04, -2.4318271e-03, -1.7522024e-03,  3.1520263e-05,\n",
              "         2.1763012e-04,  2.0734095e-03, -5.3923379e-04, -1.3230877e-03,\n",
              "        -1.2664627e-03],\n",
              "       [-5.0413323e-04, -2.4318267e-03, -1.7522019e-03,  3.1522068e-05,\n",
              "         2.1763041e-04,  2.0734104e-03, -5.3923315e-04, -1.3230859e-03,\n",
              "        -1.2664592e-03],\n",
              "       [-5.0413253e-04, -2.4318269e-03, -1.7522026e-03,  3.1522388e-05,\n",
              "         2.1762971e-04,  2.0734100e-03, -5.3923420e-04, -1.3230868e-03,\n",
              "        -1.2664613e-03],\n",
              "       [-5.0413440e-04, -2.4318264e-03, -1.7522033e-03,  3.1521689e-05,\n",
              "         2.1763035e-04,  2.0734093e-03, -5.3923373e-04, -1.3230868e-03,\n",
              "        -1.2664602e-03],\n",
              "       [-5.0413294e-04, -2.4318269e-03, -1.7522019e-03,  3.1521631e-05,\n",
              "         2.1763064e-04,  2.0734081e-03, -5.3923303e-04, -1.3230873e-03,\n",
              "        -1.2664597e-03],\n",
              "       [-5.0413242e-04, -2.4318262e-03, -1.7522031e-03,  3.1521544e-05,\n",
              "         2.1762971e-04,  2.0734109e-03, -5.3923333e-04, -1.3230863e-03,\n",
              "        -1.2664612e-03],\n",
              "       [-5.0413242e-04, -2.4318262e-03, -1.7522022e-03,  3.1520292e-05,\n",
              "         2.1762919e-04,  2.0734104e-03, -5.3923333e-04, -1.3230875e-03,\n",
              "        -1.2664595e-03],\n",
              "       [-5.0413271e-04, -2.4318281e-03, -1.7522008e-03,  3.1521602e-05,\n",
              "         2.1763064e-04,  2.0734109e-03, -5.3923199e-04, -1.3230866e-03,\n",
              "        -1.2664611e-03],\n",
              "       [-5.0413230e-04, -2.4318271e-03, -1.7521998e-03,  3.1520205e-05,\n",
              "         2.1763163e-04,  2.0734107e-03, -5.3923234e-04, -1.3230882e-03,\n",
              "        -1.2664606e-03],\n",
              "       [-5.0413277e-04, -2.4318264e-03, -1.7522022e-03,  3.1521544e-05,\n",
              "         2.1762995e-04,  2.0734118e-03, -5.3923333e-04, -1.3230868e-03,\n",
              "        -1.2664599e-03],\n",
              "       [-5.0413382e-04, -2.4318269e-03, -1.7522015e-03,  3.1520758e-05,\n",
              "         2.1763146e-04,  2.0734118e-03, -5.3923408e-04, -1.3230861e-03,\n",
              "        -1.2664616e-03],\n",
              "       [-5.0413184e-04, -2.4318269e-03, -1.7522017e-03,  3.1521340e-05,\n",
              "         2.1762971e-04,  2.0734114e-03, -5.3923274e-04, -1.3230863e-03,\n",
              "        -1.2664604e-03],\n",
              "       [-5.0413166e-04, -2.4318262e-03, -1.7522003e-03,  3.1518459e-05,\n",
              "         2.1763012e-04,  2.0734118e-03, -5.3923309e-04, -1.3230884e-03,\n",
              "        -1.2664602e-03],\n",
              "       [-5.0413329e-04, -2.4318271e-03, -1.7522012e-03,  3.1522301e-05,\n",
              "         2.1763006e-04,  2.0734114e-03, -5.3923344e-04, -1.3230870e-03,\n",
              "        -1.2664613e-03],\n",
              "       [-5.0413091e-04, -2.4318255e-03, -1.7522001e-03,  3.1519070e-05,\n",
              "         2.1762843e-04,  2.0734104e-03, -5.3923199e-04, -1.3230882e-03,\n",
              "        -1.2664623e-03],\n",
              "       [-5.0413306e-04, -2.4318271e-03, -1.7521994e-03,  3.1520729e-05,\n",
              "         2.1763105e-04,  2.0734095e-03, -5.3923269e-04, -1.3230896e-03,\n",
              "        -1.2664602e-03],\n",
              "       [-5.0413306e-04, -2.4318274e-03, -1.7522015e-03,  3.1520758e-05,\n",
              "         2.1763140e-04,  2.0734100e-03, -5.3923321e-04, -1.3230875e-03,\n",
              "        -1.2664602e-03],\n",
              "       [-5.0413189e-04, -2.4318271e-03, -1.7522015e-03,  3.1519681e-05,\n",
              "         2.1763018e-04,  2.0734107e-03, -5.3923309e-04, -1.3230877e-03,\n",
              "        -1.2664605e-03],\n",
              "       [-5.0413294e-04, -2.4318271e-03, -1.7522019e-03,  3.1521631e-05,\n",
              "         2.1763088e-04,  2.0734104e-03, -5.3923368e-04, -1.3230880e-03,\n",
              "        -1.2664606e-03],\n",
              "       [-5.0413253e-04, -2.4318262e-03, -1.7522019e-03,  3.1520787e-05,\n",
              "         2.1763000e-04,  2.0734095e-03, -5.3923356e-04, -1.3230868e-03,\n",
              "        -1.2664607e-03],\n",
              "       [-5.0413382e-04, -2.4318274e-03, -1.7522038e-03,  3.1523727e-05,\n",
              "         2.1763035e-04,  2.0734100e-03, -5.3923333e-04, -1.3230866e-03,\n",
              "        -1.2664605e-03],\n",
              "       [-5.0413207e-04, -2.4318262e-03, -1.7522026e-03,  3.1520845e-05,\n",
              "         2.1762907e-04,  2.0734100e-03, -5.3923455e-04, -1.3230877e-03,\n",
              "        -1.2664602e-03],\n",
              "       [-5.0413160e-04, -2.4318278e-03, -1.7522019e-03,  3.1520816e-05,\n",
              "         2.1763030e-04,  2.0734109e-03, -5.3923338e-04, -1.3230882e-03,\n",
              "        -1.2664609e-03],\n",
              "       [-5.0413283e-04, -2.4318267e-03, -1.7522026e-03,  3.1521893e-05,\n",
              "         2.1762989e-04,  2.0734107e-03, -5.3923368e-04, -1.3230870e-03,\n",
              "        -1.2664604e-03],\n",
              "       [-5.0413335e-04, -2.4318269e-03, -1.7522022e-03,  3.1521427e-05,\n",
              "         2.1762995e-04,  2.0734109e-03, -5.3923391e-04, -1.3230870e-03,\n",
              "        -1.2664611e-03],\n",
              "       [-5.0413364e-04, -2.4318271e-03, -1.7522012e-03,  3.1521107e-05,\n",
              "         2.1763169e-04,  2.0734095e-03, -5.3923338e-04, -1.3230859e-03,\n",
              "        -1.2664604e-03],\n",
              "       [-5.0413283e-04, -2.4318271e-03, -1.7522015e-03,  3.1519856e-05,\n",
              "         2.1762989e-04,  2.0734109e-03, -5.3923292e-04, -1.3230877e-03,\n",
              "        -1.2664588e-03],\n",
              "       [-5.0413341e-04, -2.4318260e-03, -1.7522024e-03,  3.1521427e-05,\n",
              "         2.1763018e-04,  2.0734109e-03, -5.3923309e-04, -1.3230877e-03,\n",
              "        -1.2664619e-03],\n",
              "       [-5.0413288e-04, -2.4318264e-03, -1.7522031e-03,  3.1520030e-05,\n",
              "         2.1763064e-04,  2.0734107e-03, -5.3923280e-04, -1.3230873e-03,\n",
              "        -1.2664589e-03],\n",
              "       [-5.0413399e-04, -2.4318262e-03, -1.7522022e-03,  3.1521282e-05,\n",
              "         2.1763204e-04,  2.0734123e-03, -5.3923298e-04, -1.3230863e-03,\n",
              "        -1.2664602e-03],\n",
              "       [-5.0413352e-04, -2.4318267e-03, -1.7522024e-03,  3.1520758e-05,\n",
              "         2.1763146e-04,  2.0734104e-03, -5.3923303e-04, -1.3230866e-03,\n",
              "        -1.2664592e-03],\n",
              "       [-5.0413219e-04, -2.4318269e-03, -1.7522026e-03,  3.1520787e-05,\n",
              "         2.1763099e-04,  2.0734118e-03, -5.3923234e-04, -1.3230880e-03,\n",
              "        -1.2664596e-03],\n",
              "       [-5.0413358e-04, -2.4318264e-03, -1.7522019e-03,  3.1522068e-05,\n",
              "         2.1763158e-04,  2.0734097e-03, -5.3923373e-04, -1.3230873e-03,\n",
              "        -1.2664613e-03],\n",
              "       [-5.0413265e-04, -2.4318269e-03, -1.7522017e-03,  3.1520729e-05,\n",
              "         2.1763076e-04,  2.0734111e-03, -5.3923234e-04, -1.3230880e-03,\n",
              "        -1.2664613e-03],\n",
              "       [-5.0413329e-04, -2.4318264e-03, -1.7522029e-03,  3.1521922e-05,\n",
              "         2.1763158e-04,  2.0734123e-03, -5.3923338e-04, -1.3230866e-03,\n",
              "        -1.2664604e-03],\n",
              "       [-5.0413358e-04, -2.4318269e-03, -1.7522019e-03,  3.1521195e-05,\n",
              "         2.1763041e-04,  2.0734090e-03, -5.3923274e-04, -1.3230882e-03,\n",
              "        -1.2664602e-03]], dtype=float32)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSwvHVVzVWZ5"
      },
      "source": [
        "Пример тестирования модели на полном наборе данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "mjI_sbMi3TMY",
        "outputId": "e1a9fd69-60f7-4b68-af9c-632394cfcdc9"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-04bad05bce43>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# evaluating model on full test dataset (may take time)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTEST_ON_LARGE_DATASET\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpred_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mMetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-6387ee723b42>\u001b[0m in \u001b[0;36mtest_on_dataset\u001b[0;34m(self, dataset, limit)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m#     predictions.append(self.test_on_image(img))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# return predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_on_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(32, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "# evaluating model on full test dataset (may take time)\n",
        "if TEST_ON_LARGE_DATASET:\n",
        "    pred_2 = model.test_on_dataset(d_test)\n",
        "    Metrics.print_all(d_test.labels, pred_2, 'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvyEHdxEB18o"
      },
      "source": [
        "Результат работы пайплайна обучения и тестирования выше тоже будет оцениваться. Поэтому не забудьте присылать на проверку ноутбук с выполнеными ячейками кода с демонстрациями метрик обучения, графиками и т.п. В этом пайплайне Вам необходимо продемонстрировать работу всех реализованных дополнений, улучшений и т.п.\n",
        "\n",
        "<font color=\"red\">\n",
        "Настоятельно рекомендуется после получения пайплайна с полными результатами обучения экспортировать ноутбук в pdf (файл -> печать) и прислать этот pdf вместе с самим ноутбуком.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzSKAvVI6uCW"
      },
      "source": [
        "### Тестирование модели на других наборах данных\n",
        "\n",
        "Ваша модель должна поддерживать тестирование на других наборах данных. Для удобства, Вам предоставляется набор данных test_tiny, который представляет собой малую часть (2% изображений) набора test. Ниже приведен фрагмент кода, который будет осуществлять тестирование для оценивания Вашей модели на дополнительных тестовых наборах данных.\n",
        "\n",
        "<font color=\"red\">\n",
        "Прежде чем отсылать задание на проверку, убедитесь в работоспособности фрагмента кода ниже.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdY3uTt87tqv"
      },
      "outputs": [],
      "source": [
        "final_model = Model()\n",
        "final_model.load('best')\n",
        "d_test_tiny = Dataset('test_tiny')\n",
        "pred = model.test_on_dataset(d_test_tiny)\n",
        "Metrics.print_all(d_test_tiny.labels, pred, 'test-tiny')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPvyj4gscU10"
      },
      "source": [
        "Отмонтировать Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfX35zNSvFWn"
      },
      "outputs": [],
      "source": [
        "drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMyDxCDCspcI"
      },
      "source": [
        "---\n",
        "# Дополнительные \"полезности\"\n",
        "\n",
        "Ниже приведены примеры использования различных функций и библиотек, которые могут быть полезны при выполнении данного практического задания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvLwSttCs1rB"
      },
      "source": [
        "### Измерение времени работы кода\n",
        "\n",
        "Измерять время работы какой-либо функции можно легко и непринужденно при помощи функции timeit из соответствующего модуля:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HnLVhwE9C9S"
      },
      "outputs": [],
      "source": [
        "import timeit\n",
        "\n",
        "def factorial(n):\n",
        "    res = 1\n",
        "    for i in range(1, n + 1):\n",
        "        res *= i\n",
        "    return res\n",
        "\n",
        "\n",
        "def f():\n",
        "    return factorial(n=1000)\n",
        "\n",
        "n_runs = 128\n",
        "print(f'Function f is caluclated {n_runs} times in {timeit.timeit(f, number=n_runs)}s.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fibGVEdguOOi"
      },
      "source": [
        "### Scikit-learn\n",
        "\n",
        "Для использования \"классических\" алгоритмов машинного обучения рекомендуется использовать библиотеку scikit-learn (https://scikit-learn.org/stable/). Пример классификации изображений цифр из набора данных MNIST при помощи классификатора SVM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXHnBzEfunAO"
      },
      "outputs": [],
      "source": [
        "# Standard scientific Python imports\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import datasets, classifiers and performance metrics\n",
        "from sklearn import datasets, svm, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# The digits dataset\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# The data that we are interested in is made of 8x8 images of digits, let's\n",
        "# have a look at the first 4 images, stored in the `images` attribute of the\n",
        "# dataset.  If we were working from image files, we could load them using\n",
        "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
        "# images, we know which digit they represent: it is given in the 'target' of\n",
        "# the dataset.\n",
        "_, axes = plt.subplots(2, 4)\n",
        "images_and_labels = list(zip(digits.images, digits.target))\n",
        "for ax, (image, label) in zip(axes[0, :], images_and_labels[:4]):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title('Training: %i' % label)\n",
        "\n",
        "# To apply a classifier on this data, we need to flatten the image, to\n",
        "# turn the data in a (samples, feature) matrix:\n",
        "n_samples = len(digits.images)\n",
        "data = digits.images.reshape((n_samples, -1))\n",
        "\n",
        "# Create a classifier: a support vector classifier\n",
        "classifier = svm.SVC(gamma=0.001)\n",
        "\n",
        "# Split data into train and test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data, digits.target, test_size=0.5, shuffle=False)\n",
        "\n",
        "# We learn the digits on the first half of the digits\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Now predict the value of the digit on the second half:\n",
        "predicted = classifier.predict(X_test)\n",
        "\n",
        "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
        "for ax, (image, prediction) in zip(axes[1, :], images_and_predictions[:4]):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title('Prediction: %i' % prediction)\n",
        "\n",
        "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
        "      % (classifier, metrics.classification_report(y_test, predicted)))\n",
        "disp = metrics.plot_confusion_matrix(classifier, X_test, y_test)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu3Dny5zxcVy"
      },
      "source": [
        "### Scikit-image\n",
        "\n",
        "Реализовывать различные операции для работы с изображениями можно как самостоятельно, работая с массивами numpy, так и используя специализированные библиотеки, например, scikit-image (https://scikit-image.org/). Ниже приведен пример использования Canny edge detector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TZvy_d7xc0B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "from skimage import feature\n",
        "\n",
        "\n",
        "# Generate noisy image of a square\n",
        "im = np.zeros((128, 128))\n",
        "im[32:-32, 32:-32] = 1\n",
        "\n",
        "im = ndi.rotate(im, 15, mode='constant')\n",
        "im = ndi.gaussian_filter(im, 4)\n",
        "im += 0.2 * np.random.random(im.shape)\n",
        "\n",
        "# Compute the Canny filter for two values of sigma\n",
        "edges1 = feature.canny(im)\n",
        "edges2 = feature.canny(im, sigma=3)\n",
        "\n",
        "# display results\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3),\n",
        "                                    sharex=True, sharey=True)\n",
        "\n",
        "ax1.imshow(im, cmap=plt.cm.gray)\n",
        "ax1.axis('off')\n",
        "ax1.set_title('noisy image', fontsize=20)\n",
        "\n",
        "ax2.imshow(edges1, cmap=plt.cm.gray)\n",
        "ax2.axis('off')\n",
        "ax2.set_title(r'Canny filter, $\\sigma=1$', fontsize=20)\n",
        "\n",
        "ax3.imshow(edges2, cmap=plt.cm.gray)\n",
        "ax3.axis('off')\n",
        "ax3.set_title(r'Canny filter, $\\sigma=3$', fontsize=20)\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiEWhGUQRGoH"
      },
      "source": [
        "### Tensorflow 2\n",
        "\n",
        "Для создания и обучения нейросетевых моделей можно использовать фреймворк глубокого обучения Tensorflow 2. Ниже приведен пример простейшей нейроной сети, использующейся для классификации изображений из набора данных MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDwLG7A1ReNy"
      },
      "outputs": [],
      "source": [
        "# Install TensorFlow\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbvktmLwRu8g"
      },
      "source": [
        "<font color=\"red\">\n",
        "Для эффективной работы с моделями глубокого обучения убедитесь в том, что в текущей среде Google Colab используется аппаратный ускоритель GPU или TPU. Для смены среды выберите \"среда выполнения\" -> \"сменить среду выполнения\".\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJVNOOU9Sjyf"
      },
      "source": [
        "Большое количество туториалов и примеров с кодом на Tensorflow 2 можно найти на официальном сайте https://www.tensorflow.org/tutorials?hl=ru."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVPs3pYpS0U1"
      },
      "source": [
        "Также, Вам может понадобиться написать собственный генератор данных для Tensorflow 2. Скорее всего он будет достаточно простым, и его легко можно будет реализовать, используя официальную документацию TensorFlow 2. Но, на всякий случай (если не удлось сразу разобраться или хочется вникнуть в тему более глубоко), можете посмотреть следующий отличный туториал: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwI-T0IXyN84"
      },
      "source": [
        "### Numba\n",
        "\n",
        "В некоторых ситуациях, при ручных реализациях графовых алгоритмов, выполнение многократных вложенных циклов for в python можно существенно ускорить, используя JIT-компилятор Numba (https://numba.pydata.org/).\n",
        "Примеры использования Numba в Google Colab можно найти тут:\n",
        "1. https://colab.research.google.com/github/cbernet/maldives/blob/master/numba/numba_cuda.ipynb\n",
        "2. https://colab.research.google.com/github/evaneschneider/parallel-programming/blob/master/COMPASS_gpu_intro.ipynb\n",
        "\n",
        "> Пожалуйста, если Вы решили использовать Numba для решения этого практического задания, еще раз подумайте, нужно ли это Вам, и есть ли возможность реализовать требуемую функциональность иным способом. Используйте Numba только при реальной необходимости.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxAJ00A76LcF"
      },
      "source": [
        "### Работа с zip архивами в Google Drive\n",
        "\n",
        "Запаковка и распаковка zip архивов может пригодиться при сохранении и загрузки Вашей модели. Ниже приведен фрагмент кода, иллюстрирующий помещение нескольких файлов в zip архив с последующим чтением файлов из него. Все действия с директориями, файлами и архивами должны осущетвляться с примонтированным Google Drive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJiKndOpPu_e"
      },
      "source": [
        "Создадим 2 изображения, поместим их в директорию tmp внутри PROJECT_DIR, запакуем директорию tmp в архив tmp.zip."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRwgPtv-6nMP"
      },
      "outputs": [],
      "source": [
        "PROJECT_DIR = \"/dev/prak_nn_1/\"\n",
        "arr1 = np.random.rand(100, 100, 3) * 255\n",
        "arr2 = np.random.rand(100, 100, 3) * 255\n",
        "\n",
        "img1 = Image.fromarray(arr1.astype('uint8'))\n",
        "img2 = Image.fromarray(arr2.astype('uint8'))\n",
        "\n",
        "p = \"/content/drive/MyDrive/\" + PROJECT_DIR\n",
        "\n",
        "if not (Path(p) / 'tmp').exists():\n",
        "    (Path(p) / 'tmp').mkdir()\n",
        "\n",
        "img1.save(str(Path(p) / 'tmp' / 'img1.png'))\n",
        "img2.save(str(Path(p) / 'tmp' / 'img2.png'))\n",
        "\n",
        "%cd $p\n",
        "!zip -r \"tmp.zip\" \"tmp\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MykrBSWNQQlq"
      },
      "source": [
        "Распакуем архив tmp.zip в директорию tmp2 в PROJECT_DIR. Теперь внутри директории tmp2 содержится директория tmp, внутри которой находятся 2 изображения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwSWrYIWMAus"
      },
      "outputs": [],
      "source": [
        "p = \"/content/drive/MyDrive/\" + PROJECT_DIR\n",
        "%cd $p\n",
        "!unzip -uq \"tmp.zip\" -d \"tmp2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ5D2hbe10T_",
        "outputId": "93be8191-a61c-4225-d184-03e27f502a83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/best_model.tf/ (stored 0%)\n",
            "  adding: content/best_model.tf/saved_model.pb (deflated 91%)\n",
            "  adding: content/best_model.tf/assets/ (stored 0%)\n",
            "  adding: content/best_model.tf/variables/ (stored 0%)\n",
            "  adding: content/best_model.tf/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/best_model.tf/variables/variables.index (deflated 76%)\n",
            "  adding: content/best_model.tf/keras_metadata.pb (deflated 96%)\n",
            "  adding: content/best_model.tf/fingerprint.pb (stored 0%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/file.zip /content/best_model.tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWyJCFTGt-Lv",
        "outputId": "fe0dd7f1-f0c0-4a5f-b9b9-dce3ce83e3e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  best_model26.zip\n",
            "   creating: content/best_model.tf/\n",
            "  inflating: content/best_model.tf/saved_model.pb  \n",
            "   creating: content/best_model.tf/assets/\n",
            "   creating: content/best_model.tf/variables/\n",
            "  inflating: content/best_model.tf/variables/variables.data-00000-of-00001  \n",
            "  inflating: content/best_model.tf/variables/variables.index  \n",
            "  inflating: content/best_model.tf/keras_metadata.pb  \n",
            " extracting: content/best_model.tf/fingerprint.pb  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"best_model26.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhJDm_cAvFtg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "VvLwSttCs1rB",
        "fibGVEdguOOi",
        "Uu3Dny5zxcVy"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "7af69d84c46e0da4f71f361435e72c01e713b5d1fcbc89c051c042527a934273"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}